{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw_2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMLb4W6FYLERNjER8bDfLP7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"EpWmDmEax8IR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"34907e38-4617-423a-fe99-c053fcdfe823","executionInfo":{"status":"ok","timestamp":1587007970633,"user_tz":-300,"elapsed":125772,"user":{"displayName":"Григорий Байдин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmVQBv1ZYYZM5xHeuSLChsMMY-5Lak7oZJ7CpTBw=s64","userId":"17372862430361286161"}}},"source":["# The full neural network code!\n","###############################\n","import numpy as np\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data() \n","\n","# Normalize the images.\n","train_images = (train_images / 255) #- 0.5\n","test_images = (test_images / 255) #- 0.5\n","\n","# Flatten the images.\n","train_images = train_images.reshape((-1, 784))\n","test_images = test_images.reshape((-1, 784))\n","\n","# Build the model.\n","model = Sequential([\n","  Dense(512, activation='relu', input_shape=(784,)), # 64\n","  Dense(128, activation='relu'),                     # 64\n","  Dense(32, activation='relu'),                     # 64\n","  Dense(10, activation='softmax'),                  # 10\n","])\n","\n","# Compile the model.\n","model.compile(\n","  optimizer='adam',\n","  loss='categorical_crossentropy',\n","  metrics=['accuracy'],\n",")\n","\n","# Train the model.\n","model.fit(\n","  train_images,\n","  to_categorical(train_labels),\n","  epochs=10,\n","  batch_size=32,\n",")\n","\n","# Evaluate the model.\n","model.evaluate(\n","  test_images,\n","  to_categorical(test_labels)\n",")\n","\n","# Save the model to disk.\n","model.save_weights('model.h5')\n","\n","# Load the model from disk later using:\n","# model.load_weights('model.h5')\n","\n","# Predict on the first 5 test images.\n","predictions = model.predict(test_images[:5])\n","\n","# Print our model's predictions.\n","print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n","\n","# Check our predictions against the ground truths.\n","print(test_labels[:5]) # [7, 2, 1, 0, 4]"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","60000/60000 [==============================] - 12s 205us/step - loss: 0.2076 - accuracy: 0.9384\n","Epoch 2/10\n","60000/60000 [==============================] - 12s 205us/step - loss: 0.0867 - accuracy: 0.9735\n","Epoch 3/10\n","60000/60000 [==============================] - 12s 205us/step - loss: 0.0597 - accuracy: 0.9811\n","Epoch 4/10\n","60000/60000 [==============================] - 12s 205us/step - loss: 0.0456 - accuracy: 0.9854\n","Epoch 5/10\n","60000/60000 [==============================] - 13s 214us/step - loss: 0.0370 - accuracy: 0.9883\n","Epoch 6/10\n","60000/60000 [==============================] - 12s 204us/step - loss: 0.0299 - accuracy: 0.9905\n","Epoch 7/10\n","60000/60000 [==============================] - 12s 204us/step - loss: 0.0254 - accuracy: 0.9917\n","Epoch 8/10\n","60000/60000 [==============================] - 12s 205us/step - loss: 0.0221 - accuracy: 0.9928\n","Epoch 9/10\n","60000/60000 [==============================] - 12s 207us/step - loss: 0.0206 - accuracy: 0.9934\n","Epoch 10/10\n","60000/60000 [==============================] - 12s 206us/step - loss: 0.0174 - accuracy: 0.9945\n","10000/10000 [==============================] - 0s 49us/step\n","[7 2 1 0 4]\n","[7 2 1 0 4]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X1Fz0zMODKdd","colab_type":"text"},"source":["переход на нормализацию в интервал 0 - 1   повысил точность базового набора параметров с 0.965 до 0.982\n","\n","Такого же улучшения точности не дало ни увеличение числа нейронов в слоях, ни увеличение количества слоев (при том же числе эпох обучения)\n","\n","Увеличив количество слоев и число эпох (до 10, количество нейронов по слоям: 512, 128, 32, 10), удалось повысить точность до 0.984 \n","\n","А добавив к этому нормализацию (0-1), повысил точность до 0.994"]}]}